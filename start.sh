#!/bin/bash
set -e

echo "ğŸš€ Iniciando Ollama..."
ollama serve &

# Aguarda o Ollama ficar disponÃ­vel
echo "â³ Aguardando Ollama..."
until curl -s http://localhost:11434/api/tags > /dev/null; do
  sleep 1
done

echo "âœ… Ollama disponÃ­vel"

# Baixa o modelo (ajuste conforme necessÃ¡rio)
MODEL="mistral:7b"

echo "ğŸ“¥ Baixando modelo: $MODEL"
ollama pull $MODEL

echo "ğŸ Iniciando benchmark..."
python3 benchmark.py

echo "ğŸ“Š Iniciando anÃ¡lise..."
python3 analyze.py

#docker run --rm --gpus all -v "$(pwd)/input:/root/input" -v "$(pwd)/results:/root/results" ollama-benchmark
#docker run --rm -e BENCHMARK_INPUT_DIR=/data/input -e BENCHMARK_RESULTS_DIR=/data/results -v "$(pwd)/input:/data/input" -v "$(pwd)/results:/data/results" ollama-benchmark